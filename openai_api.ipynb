{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOr182jZi5vM2hL+G6oLZdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khyojae/2025.LLM/blob/main/openai_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "model = \"gpt-3.5-turbo-0125\""
      ],
      "metadata": {
        "id": "vQzWo9BfWrdF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"ì´ê²ƒì€ ì„ë² ë”©ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ë¬¸ì¥ì…ë‹ˆë‹¤.\", \"ì„ë² ë”©ì€ ë²¡í„° ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\"]"
      ],
      "metadata": {
        "id": "NzFG6egcYawr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c20f8JsKWSjx",
        "outputId": "a2639513-f66e-48e3-9d4b-8da3c44b1b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.004123364109545946, -0.022053347900509834, 0.00014205239131115377, -0.02331695891916752, -0.015429362654685974]\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI(api_key=\"\")\n",
        "response = client.embeddings.create(\n",
        "    input=texts,\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")\n",
        "print(response.data[0].embedding[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts):\n",
        "  response = client.embeddings.create(\n",
        "      input=texts,\n",
        "      model=\"text-embedding-ada-002\"\n",
        "  )\n",
        "  return [embedding['embedding'] for embedding in response['data']]"
      ],
      "metadata": {
        "id": "QqoqigCDZ40K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "color_words = [\"red\",\"blue\",\"yellow\",\"green\",\"violet\",\"cyan\",\"black\",\"white\"]\n",
        "\n",
        "response = client.embeddings.create(\n",
        "    input=color_words,\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")\n",
        "\n",
        "color_embeddings = [data.embedding for data in response.data]\n",
        "for word,embedding in zip(color_words,color_embeddings):\n",
        "  print(f\"{word},{embedding[:5]}\")\n",
        "  print(len(embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlO5t9WDaSLC",
        "outputId": "53029df4-38ac-4120-d8b4-21738fbc20cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "red,[9.326533472631127e-06, -0.02476814016699791, -0.002384250983595848, -0.028791459277272224, -0.021199282258749008]\n",
            "1536\n",
            "blue,[0.005474964156746864, -0.007486246060580015, 0.005678507499396801, -0.03110414557158947, -0.01965053379535675]\n",
            "1536\n",
            "yellow,[0.007661858107894659, -0.024910997599363327, 0.004491548519581556, -0.02860249951481819, -0.01958620548248291]\n",
            "1536\n",
            "green,[0.01546180434525013, -0.010975971817970276, 0.025183379650115967, -0.02092933841049671, -0.005648194346576929]\n",
            "1536\n",
            "violet,[-0.006727131083607674, -0.018318135291337967, 0.0036361967213451862, -0.00567674869671464, -0.021194979548454285]\n",
            "1536\n",
            "cyan,[0.021550633013248444, -0.014010688289999962, 0.008289773017168045, -0.02929886430501938, -0.016149088740348816]\n",
            "1536\n",
            "black,[-0.015103082172572613, -0.031215764582157135, 0.00877943355590105, -0.03691864386200905, -0.01613996922969818]\n",
            "1536\n",
            "white,[0.006292110309004784, -0.02457117661833763, 0.0002028137823799625, -0.014848269522190094, -0.0052642603404819965]\n",
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#íŒŒì¸íŠœë‹\n",
        "\n",
        "response = client.files.create(\n",
        "    file=open(\"mydata.jsonl\",\"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "file_id=response.id\n",
        "print(f\"uploaded file ID: {file_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQTzl2hedgOC",
        "outputId": "2d5653a6-1942-4785-ed72-e68959154a14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uploaded file ID: file-DYceqFi9XwM2FMLXD8yYfb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "fine_tune_id = response.id\n",
        "print(f\"Fine-tune job ID: {fine_tune_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBJiZrLResvb",
        "outputId": "386001ac-4d4a-4570-b7e1-1565294f4edc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune job ID: ftjob-gXuiA6A3sORZWKpqcJW4hxhV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while True:\n",
        "  response = client.fine_tuning.jobs.retrieve(\"\")\n",
        "  status = response.status\n",
        "  if status in ['succeeded','failed']:\n",
        "    break\n",
        "  print(f\"Fine-tune job status: {status}\")\n",
        "  time.sleep(60)\n"
      ],
      "metadata": {
        "id": "Q1dIWRFrgGd7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (client ê°ì²´, status ë³€ìˆ˜, retrieve ì‘ë‹µì„ ë‹´ì€ response ê°ì²´ê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)\n",
        "\n",
        "if status == 'succeeded':\n",
        "    # 1. ğŸš¨ ìˆ˜ì •: response['fine_tuned_model'] ëŒ€ì‹  response.fine_tuned_model ì‚¬ìš©\n",
        "    final_model_name = response.fine_tuned_model\n",
        "\n",
        "    if final_model_name:\n",
        "\n",
        "        # 2. ğŸš¨ ìˆ˜ì •: completions ëŒ€ì‹  chat.completions.create ì‚¬ìš© (gpt-3.5-turbo ê¸°ë°˜ ëª¨ë¸ì¼ ê²½ìš° í•„ìˆ˜)\n",
        "        response_chat = client.chat.completions.create(\n",
        "            model=final_model_name,\n",
        "            # 3. ğŸš¨ ìˆ˜ì •: prompt ëŒ€ì‹  messages ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© (Chat API í˜•ì‹)\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Good night'\"}\n",
        "            ],\n",
        "            max_tokens=50\n",
        "        )\n",
        "\n",
        "        # 4. ğŸš¨ ì‘ë‹µ í…ìŠ¤íŠ¸ ì ‘ê·¼ ë°©ì‹ ë³€ê²½ (.text ëŒ€ì‹  .content)\n",
        "        output_text = response_chat.choices[0].message.content.strip()\n",
        "        print(f\"âœ… Fine-tuned model output: {output_text}\")\n",
        "    else:\n",
        "        print(\"âŒ ì˜¤ë¥˜: íŒŒì¸íŠœë‹ ì‘ì—…ì€ ì„±ê³µí–ˆìœ¼ë‚˜, ìƒì„±ëœ ëª¨ë¸ ì´ë¦„(`fine_tuned_model`)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ Fine-tuning job failed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmgcztrN0Hv9",
        "outputId": "ea28e502-fbb3-49db-b096-6a61f2c524cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fine-tuned model output: Bonne nuit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "# (client ê°ì²´ëŠ” API í‚¤ì™€ í•¨ê»˜ ì´ˆê¸°í™”ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)\n",
        "# client = OpenAI(api_key=\"...\")\n",
        "\n",
        "def edit_text(input_text: str, instruction: str) -> str:\n",
        "    \"\"\"\n",
        "    GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ì§€ì¹¨ì„ ì ìš©í•˜ì—¬ í¸ì§‘í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    # í…ìŠ¤íŠ¸ í¸ì§‘ì„ ìš”ì²­í•˜ëŠ” ëª…í™•í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„±\n",
        "    system_prompt = (\n",
        "        \"You are an expert text editor. Your task is to apply the user's instruction \"\n",
        "        \"to the provided input text and return ONLY the resulting, edited text.\"\n",
        "    )\n",
        "\n",
        "    # ì‚¬ìš©ìì˜ ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ì§€ì¹¨ì„ ê²°í•©\n",
        "    user_prompt = f\"Original text: \\\"{input_text}\\\"\\nInstruction: \\\"{instruction}\\\"\"\n",
        "\n",
        "    try:\n",
        "        # ğŸš¨ ìˆ˜ì •: client.chat.completions.create ì‚¬ìš©\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",  # í…ìŠ¤íŠ¸ í¸ì§‘ì— ì í•©í•œ ëª¨ë¸\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            max_tokens=256,\n",
        "            temperature=0.1 # í¸ì§‘ì€ ì°½ì˜ì„±ë³´ë‹¤ ì •í™•ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ë‚®ì€ ì˜¨ë„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "        )\n",
        "\n",
        "        # ğŸš¨ ì‘ë‹µì—ì„œ ìµœì¢… í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during editing: {e}\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. ì‹¤í–‰ ì½”ë“œ\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "\n",
        "print(f\"Edited_text: {edited_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFipYtHA22lr",
        "outputId": "3a7ca980-ba6f-4cdf-dddb-a240ff53e708"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edited_text: The quick brown cat jumped over the lazy dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "# ğŸš¨ 1. API í‚¤ ì„¤ì • (ì œê³µí•´ì£¼ì‹  í‚¤ ë°˜ì˜)\n",
        "API_KEY = \"\"\n",
        "\n",
        "# 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "try:\n",
        "    # client ê°ì²´ë¥¼ API í‚¤ì™€ í•¨ê»˜ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    print(\"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "def edit_text(input_text: str, instruction: str) -> str:\n",
        "    \"\"\"\n",
        "    OpenAI Chat Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í¸ì§‘í•©ë‹ˆë‹¤.\n",
        "    (Edit APIê°€ ì œê±°ë˜ì–´ Chat APIë¡œ ëŒ€ì²´)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",  # í…ìŠ¤íŠ¸ í¸ì§‘ì— ì í•©í•œ ëª¨ë¸\n",
        "            messages=[\n",
        "                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: í¸ì§‘ ì‘ì—…ì— ëŒ€í•œ ì—­í• ì„ ì •ì˜í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert text editor. Your task is to apply the user's instruction to the provided input text and return ONLY the resulting, edited text.\"},\n",
        "                # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸: ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ì§€ì¹¨ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
        "                {\"role\": \"user\", \"content\": f\"Please edit the following text: '{input_text}'. Instruction: {instruction}\"}\n",
        "            ],\n",
        "            max_tokens=256,\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "        # v1.x.x ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        # API ì˜¤ë¥˜ (ì˜ˆ: ê¶Œí•œ ë¬¸ì œ, í† í° ë¬¸ì œ) ë°œìƒ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜\n",
        "        return f\"í…ìŠ¤íŠ¸ í¸ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# ì‹¤í–‰ ì˜ˆì‹œ\n",
        "# -------------------------------------------------------------\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print(f\"\\n--- ê²°ê³¼ ---\")\n",
        "print(f\"Original text: {input_text}\")\n",
        "print(f\"Instruction: {instruction}\")\n",
        "print(f\"Edited text: {edited_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5--VFqI4KHa",
        "outputId": "5960f403-98cf-44e8-b856-4c9c1f37607b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ.\n",
            "\n",
            "--- ê²°ê³¼ ---\n",
            "Original text: The quick brown fox jumps over the lazy dog.\n",
            "Instruction: Change 'fox' to 'cat' and change the tense to past.\n",
            "Edited text: The quick brown cat jumped over the lazy dog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def moderate_text(input_text):\n",
        "  response = client.moderations.create(\n",
        "      input=input_text,\n",
        "      model=\"omni-moderation-latest\"\n",
        "  )\n",
        "  return response.results\n",
        "\n",
        "input_texts =[\n",
        "    \"I want to harm myself.\",\n",
        "    \"You are an amazing person!\",\n",
        "    \"Let's meet at 8 pm.\",\n",
        "    \"I hate you and I want to hurt you\"\n",
        "]\n",
        "\n",
        "for text in input_texts:\n",
        "  moderation_result = moderate_text(text)\n",
        "  print(f\"Input: {text}\")\n",
        "  print(f\"Moderation result: {moderation_result}\")\n",
        "  print(\"-\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCHA0V835MHs",
        "outputId": "6701b04b-24e2-4fe2-e554-d5c33181f5e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I want to harm myself.\n",
            "Moderation result: [Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=False, illicit_violent=False, self_harm=True, self_harm_instructions=False, self_harm_intent=True, sexual=False, sexual_minors=False, violence=True, violence_graphic=False, harassment/threatening=False, hate/threatening=False, illicit/violent=False, self-harm/intent=True, self-harm/instructions=False, self-harm=True, sexual/minors=False, violence/graphic=False), category_applied_input_types=CategoryAppliedInputTypes(harassment=['text'], harassment_threatening=['text'], hate=['text'], hate_threatening=['text'], illicit=['text'], illicit_violent=['text'], self_harm=['text'], self_harm_instructions=['text'], self_harm_intent=['text'], sexual=['text'], sexual_minors=['text'], violence=['text'], violence_graphic=['text'], harassment/threatening=['text'], hate/threatening=['text'], illicit/violent=['text'], self-harm/intent=['text'], self-harm/instructions=['text'], self-harm=['text'], sexual/minors=['text'], violence/graphic=['text']), category_scores=CategoryScores(harassment=0.0005689574642911562, harassment_threatening=0.0007696328798416084, hate=1.7952796934677738e-05, hate_threatening=8.888084683809127e-06, illicit=0.0052831760048374175, illicit_violent=2.4156629828672456e-05, self_harm=0.9746147566202028, self_harm_instructions=0.00028151729221049604, self_harm_intent=0.9885491614739444, sexual=8.559006367452268e-05, sexual_minors=6.205049602300744e-06, violence=0.4023404152908457, violence_graphic=0.001610160050623429, harassment/threatening=0.0007696328798416084, hate/threatening=8.888084683809127e-06, illicit/violent=2.4156629828672456e-05, self-harm/intent=0.9885491614739444, self-harm/instructions=0.00028151729221049604, self-harm=0.9746147566202028, sexual/minors=6.205049602300744e-06, violence/graphic=0.001610160050623429), flagged=True)]\n",
            "----------------------------------------\n",
            "Input: You are an amazing person!\n",
            "Moderation result: [Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=False, illicit_violent=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, harassment/threatening=False, hate/threatening=False, illicit/violent=False, self-harm/intent=False, self-harm/instructions=False, self-harm=False, sexual/minors=False, violence/graphic=False), category_applied_input_types=CategoryAppliedInputTypes(harassment=['text'], harassment_threatening=['text'], hate=['text'], hate_threatening=['text'], illicit=['text'], illicit_violent=['text'], self_harm=['text'], self_harm_instructions=['text'], self_harm_intent=['text'], sexual=['text'], sexual_minors=['text'], violence=['text'], violence_graphic=['text'], harassment/threatening=['text'], hate/threatening=['text'], illicit/violent=['text'], self-harm/intent=['text'], self-harm/instructions=['text'], self-harm=['text'], sexual/minors=['text'], violence/graphic=['text']), category_scores=CategoryScores(harassment=0.0006602641499937108, harassment_threatening=1.0391067562761452e-05, hate=6.10885510164857e-06, hate_threatening=1.5057017254045334e-07, illicit=6.40200641038395e-06, illicit_violent=4.198630823683514e-06, self_harm=1.1235328063870752e-05, self_harm_instructions=1.1300808333434096e-06, self_harm_intent=5.144221374220898e-06, sexual=1.15919343186331e-05, sexual_minors=1.3007128466476034e-06, violence=0.0005323933551511255, violence_graphic=4.832563818725537e-06, harassment/threatening=1.0391067562761452e-05, hate/threatening=1.5057017254045334e-07, illicit/violent=4.198630823683514e-06, self-harm/intent=5.144221374220898e-06, self-harm/instructions=1.1300808333434096e-06, self-harm=1.1235328063870752e-05, sexual/minors=1.3007128466476034e-06, violence/graphic=4.832563818725537e-06), flagged=False)]\n",
            "----------------------------------------\n",
            "Input: Let's meet at 8 pm.\n",
            "Moderation result: [Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=False, illicit_violent=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, harassment/threatening=False, hate/threatening=False, illicit/violent=False, self-harm/intent=False, self-harm/instructions=False, self-harm=False, sexual/minors=False, violence/graphic=False), category_applied_input_types=CategoryAppliedInputTypes(harassment=['text'], harassment_threatening=['text'], hate=['text'], hate_threatening=['text'], illicit=['text'], illicit_violent=['text'], self_harm=['text'], self_harm_instructions=['text'], self_harm_intent=['text'], sexual=['text'], sexual_minors=['text'], violence=['text'], violence_graphic=['text'], harassment/threatening=['text'], hate/threatening=['text'], illicit/violent=['text'], self-harm/intent=['text'], self-harm/instructions=['text'], self-harm=['text'], sexual/minors=['text'], violence/graphic=['text']), category_scores=CategoryScores(harassment=3.799845147518645e-05, harassment_threatening=2.0027376671813928e-05, hate=8.888084683809127e-06, hate_threatening=1.1125607488784412e-06, illicit=3.8596609058077356e-05, illicit_violent=2.8240807799315707e-05, self_harm=1.1959857805023158e-05, self_harm_instructions=4.069457790466838e-06, self_harm_intent=0.00021217710837818755, sexual=6.070755804415097e-05, sexual_minors=7.722191834067996e-06, violence=0.0005775117631028116, violence_graphic=5.649793328376294e-06, harassment/threatening=2.0027376671813928e-05, hate/threatening=1.1125607488784412e-06, illicit/violent=2.8240807799315707e-05, self-harm/intent=0.00021217710837818755, self-harm/instructions=4.069457790466838e-06, self-harm=1.1959857805023158e-05, sexual/minors=7.722191834067996e-06, violence/graphic=5.649793328376294e-06), flagged=False)]\n",
            "----------------------------------------\n",
            "Input: I hate you and I want to hurt you\n",
            "Moderation result: [Moderation(categories=Categories(harassment=True, harassment_threatening=True, hate=False, hate_threatening=False, illicit=False, illicit_violent=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=True, violence_graphic=False, harassment/threatening=True, hate/threatening=False, illicit/violent=False, self-harm/intent=False, self-harm/instructions=False, self-harm=False, sexual/minors=False, violence/graphic=False), category_applied_input_types=CategoryAppliedInputTypes(harassment=['text'], harassment_threatening=['text'], hate=['text'], hate_threatening=['text'], illicit=['text'], illicit_violent=['text'], self_harm=['text'], self_harm_instructions=['text'], self_harm_intent=['text'], sexual=['text'], sexual_minors=['text'], violence=['text'], violence_graphic=['text'], harassment/threatening=['text'], hate/threatening=['text'], illicit/violent=['text'], self-harm/intent=['text'], self-harm/instructions=['text'], self-harm=['text'], sexual/minors=['text'], violence/graphic=['text']), category_scores=CategoryScores(harassment=0.8418385774312293, harassment_threatening=0.571133284813838, hate=0.0011943122644890883, hate_threatening=5.112579049909173e-05, illicit=0.020047808528391945, illicit_violent=0.0020498297650505624, self_harm=0.0005609433189649217, self_harm_instructions=0.00021587874268682574, self_harm_intent=0.0002964673556066361, sexual=0.0007129746438779075, sexual_minors=7.14190139989638e-06, violence=0.8497739359820049, violence_graphic=4.044814978420809e-05, harassment/threatening=0.571133284813838, hate/threatening=5.112579049909173e-05, illicit/violent=0.0020498297650505624, self-harm/intent=0.0002964673556066361, self-harm/instructions=0.00021587874268682574, self-harm=0.0005609433189649217, sexual/minors=7.14190139989638e-06, violence/graphic=4.044814978420809e-05), flagged=True)]\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def generate_image(prompt):\n",
        "  response = client.images.generate(\n",
        "      model=\"dall-e-3\",\n",
        "      prompt=prompt,\n",
        "      n=1,\n",
        "      size=\"1024x1024\"\n",
        "  )\n",
        "  image_url = response.data[0].url\n",
        "  return image_url"
      ],
      "metadata": {
        "id": "qs9UFYAV_McD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(image_url, filename):\n",
        "  response = requests.get(image_url)\n",
        "  image = Image.open(BytesIO(response.content))\n",
        "  image.save(filename)\n",
        "\n",
        "prompt = \"A futuristic cityscape at sunset\"\n",
        "\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URLl {image_url}\")\n",
        "\n",
        "save_image(image_url, \"generated_image.png\")\n",
        "print(\"Image saved as generated_imaged.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nltYHT9z546t",
        "outputId": "13e1436a-20a9-45de-cf30-34f9bbe6972e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URLl https://oaidalleapiprodscus.blob.core.windows.net/private/org-lcpTesCjoMdoJWif6kSXIkr7/user-pBTdfx2AoCTgRW6QBhKkmJgt/img-wzDv3Z5J7sJuN9KJ3KJr3fd0.png?st=2025-11-29T06%3A42%3A18Z&se=2025-11-29T08%3A42%3A18Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=77e5a8ec-6bd1-4477-8afc-16703a64f029&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-11-29T07%3A42%3A18Z&ske=2025-11-30T07%3A42%3A18Z&sks=b&skv=2024-08-04&sig=cgTDSBZe8Jb4Yo49fFyNxunPF2XIn36ybTMbpKOpxZI%3D\n",
            "Image saved as generated_imaged.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a white siamese cat\"\n",
        "\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URLl {image_url}\")\n",
        "\n",
        "save_image(image_url, \"generated_image.png\")\n",
        "print(\"Image saved as generated_imaged.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWv7jSGkB4Yc",
        "outputId": "bf45055e-340e-4cd3-de8c-8608dcaa963f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URLl https://oaidalleapiprodscus.blob.core.windows.net/private/org-lcpTesCjoMdoJWif6kSXIkr7/user-pBTdfx2AoCTgRW6QBhKkmJgt/img-VjQ2lLkE2akbeiGRAhArqJ5M.png?st=2025-11-29T06%3A42%3A37Z&se=2025-11-29T08%3A42%3A37Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=cc612491-d948-4d2e-9821-2683df3719f5&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-11-29T07%3A42%3A37Z&ske=2025-11-30T07%3A42%3A37Z&sks=b&skv=2024-08-04&sig=mt%2BigaeOxGcfOrRIbQAamCoSf0MomyU2vp5BeBf80Gw%3D\n",
            "Image saved as generated_imaged.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a white siamese cat\"\n",
        "\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URLl {image_url}\")\n",
        "\n",
        "save_image(image_url, \"generated_image.png\")\n",
        "print(\"Image saved as generated_imaged.png\")"
      ],
      "metadata": {
        "id": "lGe1PppxCNqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3369db1d-99e8-400b-9246-2f685e177083"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URLl https://oaidalleapiprodscus.blob.core.windows.net/private/org-lcpTesCjoMdoJWif6kSXIkr7/user-pBTdfx2AoCTgRW6QBhKkmJgt/img-R4GJvwqvig7CNyIseKjcCVnz.png?st=2025-11-29T06%3A42%3A56Z&se=2025-11-29T08%3A42%3A56Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=7daae675-7b42-4e2e-ab4c-8d8419a28d99&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-11-29T07%3A31%3A27Z&ske=2025-11-30T07%3A31%3A27Z&sks=b&skv=2024-08-04&sig=hiKg5xbCe3L05x%2BmeNhoSY4xmNXr3eCi70cfuwpKT0Y%3D\n",
            "Image saved as generated_imaged.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code(prompt, model=\"gpt-3.5-turbo-instruct\", max_tokens=1000):\n",
        "    \"\"\"\n",
        "    OpenAI Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (v1.0.0 ì´ìƒ).\n",
        "\n",
        "    Args:\n",
        "        prompt (str): ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ì‚¬ìš©ì ìš”ì²­ í”„ë¡¬í”„íŠ¸.\n",
        "        model (str): ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„. (ê¸°ë³¸ê°’: gpt-3.5-turbo-instruct)\n",
        "        max_tokens (int): ìƒì„±í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ í† í° ìˆ˜.\n",
        "\n",
        "    Returns:\n",
        "        str or None: ìƒì„±ëœ ì½”ë“œ ë¬¸ìì—´ ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ ì‹œ None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # â­ï¸ v1.0.0 ë°©ì‹: client ê°ì²´ë¥¼ í†µí•´ í˜¸ì¶œ\n",
        "        response = client.completions.create(\n",
        "            model=model,\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0, # ì½”ë“œ ìƒì„±ì€ ë³´í†µ ë‚®ì€ temperature(0)ë¥¼ ì‚¬ìš©\n",
        "            n=1,\n",
        "            stop=None\n",
        "        )\n",
        "\n",
        "        # ìƒì„±ëœ ì½”ë“œë¥¼ ì‘ë‹µì—ì„œ ì¶”ì¶œ (ì´ ë¶€ë¶„ì€ ì´ì „ê³¼ ë™ì¼í•œ ì†ì„±ì„ ì‚¬ìš©)\n",
        "        code = response.choices[0].text.strip()\n",
        "        return code\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "GB_jkiEYCfXR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a C code that computes Fibonacci number using memoization.\"\n",
        "generated_code = generate_code(prompt)\n",
        "if generated_code:\n",
        "  print(\"Generated Code:\\n\")\n",
        "  print(generated_code)\n",
        "else:\n",
        "  print(\"Failed to generate code\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfSmGo-uEWUG",
        "outputId": "158439e7-cdd5-411a-ebef-1970af21081f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            "\n",
            "#include <stdio.h>\n",
            "\n",
            "// Function to compute Fibonacci number using memoization\n",
            "int fib(int n, int memo[])\n",
            "{\n",
            "    // Base cases\n",
            "    if (n == 0 || n == 1)\n",
            "        return n;\n",
            "\n",
            "    // Check if the value is already computed\n",
            "    if (memo[n] != -1)\n",
            "        return memo[n];\n",
            "\n",
            "    // Compute and store the value in the memo array\n",
            "    memo[n] = fib(n-1, memo) + fib(n-2, memo);\n",
            "\n",
            "    // Return the computed value\n",
            "    return memo[n];\n",
            "}\n",
            "\n",
            "int main()\n",
            "{\n",
            "    int n;\n",
            "    printf(\"Enter the value of n: \");\n",
            "    scanf(\"%d\", &n);\n",
            "\n",
            "    // Initialize the memo array with -1\n",
            "    int memo[n+1];\n",
            "    for (int i = 0; i <= n; i++)\n",
            "        memo[i] = -1;\n",
            "\n",
            "    // Call the fib function and print the result\n",
            "    printf(\"Fibonacci number at position %d is %d\", n, fib(n, memo));\n",
            "\n",
            "    return 0;\n",
            "}\n",
            "\n",
            "/*\n",
            "Output:\n",
            "\n",
            "Enter the value of n: 6\n",
            "Fibonacci number at position 6 is 8\n",
            "*/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    with open(file_name, \"rb\") as file_handle:\n",
        "        # v1.0.0 ë¬¸ë²•: client.files.upload() ì‚¬ìš©\n",
        "        upload_response = client.files.upload(\n",
        "            file=file_handle,\n",
        "            purpose='fine-tune'\n",
        "        )\n",
        "\n",
        "    print(\"Upload Response:\", upload_response)\n",
        "    file_id = upload_response.id\n",
        "    print(f\"ì—…ë¡œë“œëœ íŒŒì¼ ID: {file_id}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "\n",
        "if file_id:\n",
        "    # 7. ëª¨ë“  íŒŒì¼ ëª©ë¡ ì¡°íšŒ (List all files)\n",
        "    print(\"\\n--- 2. íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹œì‘ ---\")\n",
        "    try:\n",
        "        # v1.0.0 ë¬¸ë²•: client.files.list() ì‚¬ìš©\n",
        "        list_response = client.files.list()\n",
        "        print(\"List Response:\", list_response)\n",
        "    except Exception as e:\n",
        "        print(f\"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "    # 8. íŠ¹ì • íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (Retrieve a specific file)\n",
        "    print(\"\\n--- 3. íŠ¹ì • íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹œì‘ ---\")\n",
        "    try:\n",
        "        # v1.0.0 ë¬¸ë²•: client.files.retrieve(file_id) ì‚¬ìš©\n",
        "        retrieve_response = client.files.retrieve(file_id)\n",
        "        print(\"Retrieve Response:\", retrieve_response)\n",
        "    except Exception as e:\n",
        "        print(f\"íŠ¹ì • íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "    # 9. íŒŒì¼ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° (Retrieve file content)\n",
        "    print(\"\\n--- 4. ì—…ë¡œë“œ íŒŒì¼ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ ---\")\n",
        "    try:\n",
        "        # v1.0.0 ë¬¸ë²•: client.files.content(file_id)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚´ìš© ìŠ¤íŠ¸ë¦¼ì„ ë¶ˆëŸ¬ì˜´\n",
        "        content_response = client.files.content(file_id)\n",
        "        file_content = content_response.read().decode('utf-8')\n",
        "\n",
        "        print(\"File Content (ì¼ë¶€):\")\n",
        "        print(file_content[:150] + \"\\n...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"íŒŒì¼ ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "    # 10. íŒŒì¼ ì‚­ì œ (Delete a file)\n",
        "    print(\"\\n--- 5. íŒŒì¼ ì‚­ì œ ì‹œì‘ ---\")\n",
        "    try:\n",
        "        # v1.0.0 ë¬¸ë²•: client.files.delete(file_id) ì‚¬ìš©\n",
        "        delete_response = client.files.delete(file_id)\n",
        "        print(\"Delete Response:\", delete_response)\n",
        "\n",
        "        if delete_response.deleted:\n",
        "            print(f\"íŒŒì¼ ID **{file_id}**ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ‰\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA1MtrN7E07m",
        "outputId": "41dd38ca-432b-49d9-db1a-65c4a0b5a58f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: 'Files' object has no attribute 'upload'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(file_path,model=\"whisper-1\",response_format=\"json\",temperature=0.1,language=None,prompt=None):\n",
        "  with open(file_path, \"rb\") as audio_file:\n",
        "    response = client.Audio.transcribe(\n",
        "        file=audio_file,\n",
        "        model=model,\n",
        "        response_format = response_format,\n",
        "        temperature=temperature,\n",
        "        language=language,\n",
        "        prompt=prompt\n",
        "    )\n",
        "  return response"
      ],
      "metadata": {
        "id": "-QizJ8ZiHFiF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "# client = openai.OpenAI() ê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\", temperature=0.1, language=None, prompt=None):\n",
        "  \"\"\"OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (v1.0.0 ì´ìƒ).\"\"\"\n",
        "  try:\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "      # â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: client.Audio.transcribe -> client.audio.transcriptions.create\n",
        "      response = client.audio.transcriptions.create(\n",
        "          file=audio_file,\n",
        "          model=model,\n",
        "          response_format=response_format,\n",
        "          temperature=temperature,\n",
        "          language=language,\n",
        "          prompt=prompt\n",
        "      )\n",
        "\n",
        "      # JSON í˜•ì‹ ì‘ë‹µì„ ê°€ì •í•  ê²½ìš° í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ\n",
        "      if response_format == \"json\":\n",
        "          return response.text\n",
        "      else: # text, srt, vtt ë“± ë‹¤ë¥¸ í˜•ì‹ì„ ê°€ì •í•  ê²½ìš°\n",
        "          return response\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      return f\"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\"\n",
        "  except Exception as e:\n",
        "      return f\"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "# # ì‚¬ìš© ì˜ˆì‹œ\n",
        "file_path = 'Dracula.mp3'\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iCri4cQHuMe",
        "outputId": "9c071da3-6112-4053-a83c-d743abe63ec0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response:\n",
            "Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse. The candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders, searching for some precious grail. We are the embers that glow in the winter, the diamonds in the mine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds. When the great battle commences, surely the light will prevail. We will break down his defenses, he will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds.\n"
          ]
        }
      ]
    }
  ]
}