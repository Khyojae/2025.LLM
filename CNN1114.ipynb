{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khyojae/2025.LLM/blob/main/CNN1114.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QrKn5-ZvJns0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LEwF_puKQVi",
        "outputId": "1016097d-1439-41cb-e83f-d2bd6ec54c67"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1746s\u001b[0m 557ms/step - accuracy: 0.7183 - loss: 0.8188\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1755s\u001b[0m 555ms/step - accuracy: 0.8106 - loss: 0.5451\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1752s\u001b[0m 551ms/step - accuracy: 0.8328 - loss: 0.4876\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1745s\u001b[0m 558ms/step - accuracy: 0.8425 - loss: 0.4531\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1746s\u001b[0m 559ms/step - accuracy: 0.8501 - loss: 0.4277\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1737s\u001b[0m 556ms/step - accuracy: 0.8647 - loss: 0.3890\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1774s\u001b[0m 560ms/step - accuracy: 0.8739 - loss: 0.3668\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1761s\u001b[0m 559ms/step - accuracy: 0.8818 - loss: 0.3376\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1756s\u001b[0m 562ms/step - accuracy: 0.8895 - loss: 0.3160\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1753s\u001b[0m 559ms/step - accuracy: 0.8944 - loss: 0.3029\n",
            "\n",
            "# 8. Fine-tuning 학습 시작 (일부 백본 재학습)\n",
            "Epoch 1/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2127s\u001b[0m 678ms/step - accuracy: 0.7727 - loss: 0.6546\n",
            "Epoch 2/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2110s\u001b[0m 675ms/step - accuracy: 0.8319 - loss: 0.4823\n",
            "Epoch 3/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2116s\u001b[0m 677ms/step - accuracy: 0.8490 - loss: 0.4343\n",
            "Epoch 4/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2119s\u001b[0m 678ms/step - accuracy: 0.8611 - loss: 0.3942\n",
            "Epoch 5/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2113s\u001b[0m 675ms/step - accuracy: 0.8652 - loss: 0.3883\n",
            "Epoch 6/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2125s\u001b[0m 676ms/step - accuracy: 0.8742 - loss: 0.3627\n",
            "Epoch 7/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2118s\u001b[0m 675ms/step - accuracy: 0.8760 - loss: 0.3511\n",
            "Epoch 8/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2112s\u001b[0m 672ms/step - accuracy: 0.8812 - loss: 0.3379\n",
            "Epoch 9/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2130s\u001b[0m 674ms/step - accuracy: 0.8868 - loss: 0.3200\n",
            "Epoch 10/10\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2123s\u001b[0m 675ms/step - accuracy: 0.8971 - loss: 0.2997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78a537fb9370>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "NUM_CLASSES=10\n",
        "INPUT_SHAPE = (32,32,3)\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) =cifar10.load_data()\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# x_train 데이터를 MobileNetV2 권장 전처리 함수와 함께 사용할 수 있도록 float32로 변환\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(224,224,3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, UpSampling2D\n",
        "resized = tf.keras.layers.UpSampling2D(size=(7, 7), interpolation='bilinear')(inputs)\n",
        "\n",
        "preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(resized)\n",
        "x = base_model(preprocessed, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "preds = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=preds)\n",
        "\n",
        "train_datagen =ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow(x_train, y_train, batch_size=16)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "model.fit(train_gen,\n",
        "          steps_per_epoch=len(x_train)//16,\n",
        "          epochs=10)\n",
        "\n",
        "\n",
        "\n",
        "for layer in base_model.layers[-10:]:\n",
        "  layer.trainable= True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n# 8. Fine-tuning 학습 시작 (일부 백본 재학습)\")\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    # ⭐ 오류 수정: len(16) 대신 len(x_train) // 16 사용\n",
        "    steps_per_epoch=len(x_train) // 16,\n",
        "    epochs=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n# 9. 최종 모델 평가\")\n",
        "res = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(f\"정확률은 {res[1]*100:.2f}% 입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsAPfG9qrNpG",
        "outputId": "5b1dabb6-d27b-4722-87cd-fa25ac0ed28a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# 9. 최종 모델 평가\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 1s/step - accuracy: 0.8842 - loss: 0.3574\n",
            "정확률은 88.25% 입니다.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKIYdiO1FCqC3qQoUjR0vM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}